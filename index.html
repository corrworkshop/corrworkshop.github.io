---
layout: coverpage
---

<div class="banner">
  <img src="images/banner.jpg" alt="Causal and Object-Centric Computer Vision for Robot Learning" class="banner-img">
  <div class="banner-text">
    <h1>Causal and Object-Centric Representations for Robot Learning</h1>
    <p>June 17, CVPR 2024 Workshop</p>
  </div>
</div>

<div class="row">
<p>
  Current approaches in computer vision and machine learning primarily rely on identifying statistical correlations within massive datasets. This reliance limits their efficacy in areas that necessitate higher-order cognition, such as domain generalization and planning. A foundational approach to overcome these limitations involves incorporating principles of causality into the processing of large datasets. Similar to classic AI methodologies, causal inference usually assumes that the causal variables of interest are provided externally. However, real-world data, often encapsulated in high-dimensional, low-level observations (e.g., RGB pixels in a video), generally lacks organization into meaningful causal units. <strong>Causal Representation Learning</strong> offers a promising resolution by melding causality principles, enabling models to discern cause-and-effect relationships and thereby generate controllable representations. From another perspective, <strong>Object-centric Representation Learning</strong> focuses on decomposing sensory inputs, such as images and videos, into set-based representations where distinct vectors represent different objects. Employing such structured representations enhances the generalization, interpretability, and robustness of subsequent task performance.
</p>
<p>  
  Object-centric and causal representation learning methods aim to overcome the challenges posed by conventional models that rely solely on correlations, offering a new pathway for advancing computer vision, particularly in dynamic and complex environments like robotics. Importantly, with the current vision and embodied AI systems, it is not obvious how to model interventions, counterfactuals, and hypotheticals without resorting to severe manual hand-engineering. While much can be done with significant supervision, ideally, robots and embodied agents should learn autonomously from the simulated environment.
</p>
<p>
  This workshop aims to bring together researchers from structured (object-centric and causal) representation learning and robotics-oriented computer vision. To help integrate ideas from these areas, we invite researchers that want from Embodied AI, Causality and Representation Learning. We hope that this creates opportunities for disscusion, presenting cutting-edge research, establishing new collaborations and identifying future research directions.
</p>
<p>
  In particular, we welcome contributions in the direction of:
  <ul>
    <li>Causal representation learning: how to learn representations with deep networks that conform to cause-and-effect transformations in the pixel space,</li>
    <li>Object-centric learning: how to learn representations that are object-specific without requiring closed-world manual annotations</li>
    <li>Scaling stuctured representations: how to learn object-centric learning and causal represenations on real-world image and video datasets such MS COCO images or videos from YouTube.</li>
    <li>Downstream applications of structured representations: how to use causal and object-centric representations for tasks such as reinforcement learning, planning, and decision making.</li>
    <li>Learning of interventions: how can a robot algorithm can transform and control diffent components of the environment to achieve certain goals.</li>
    <li>Causal reinforcement for Embodied AI: how to best learn RL policies to achieve goals if we know cause-and-effects relations are known.</li>
    <li>Benchmarks that quantify the benefits of causal and object-centric representations (e.g. systematic generalization, OOD performance, robustness wrt. interventions, etc.) </li>
    <li>Relations and possible synergies to foundation models</li>
  </ul>
</p>

</div>

<div id="organizers" class="row">
<h2>Organizers</h2>
<div class="break"></div>
<ul>
  <li><a href="https://www.egavves.com/">Efstratios Gavves</a> (University of Amsterdam)</li>
  <li><a href="https://roozbehm.info/">Roozbeh Mottaghi</a> (Meta)</li>
  <li><a href="https://www.francescolocatello.com/">Francesco Locatello</a> (ISTA)</li>
  <li><a href="https://zadaianchuk.github.io/">Andrii Zadaianchuk</a> (University of Amsterdam)</li>
  <li><a href="https://rutadesai.github.io/">Ruta Desai</a> (Meta)</li>
  <li><a href="https://acsweb.ucsd.edu/~pparasha/">Priyam Parashar</a> (Meta)</li>
  <li><a href="https://spatki.gitlab.io/">Siddharth Patki</a> (Meta)</li>
  <li><a href="https://phlippe.github.io">Phillip Lippe</a> (University of Amsterdam)</li>

</ul>
</div>